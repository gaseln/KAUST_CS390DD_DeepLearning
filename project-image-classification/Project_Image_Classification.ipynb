{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "quHwuvnL_N9o"
   },
   "source": [
    "# Project 1: Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1JWfOd3AVO9J"
   },
   "source": [
    "## Task 0: Getting Started\n",
    "\n",
    "Read the getting started guide titled **\"Python for Deep Learning\"** and get familiar with Python and PyTorch. Read the provided code below and get familiar with the commands and their parameters to understand what the code is trying to do. We recommend to spend a fair amount of time to understand all the different parts of the code. This understanding will be important for this and future projects.\n",
    "\n",
    "The goal of this project is to implement the *“Hello World!”* program of deep learning: designing and training a network that performs image classification. The dataset we will be using is CIFAR10 which is a large set of images that are classified into 10 classes (airplane, bird, cat, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wgsyd2YsVO9L"
   },
   "source": [
    "## Task 1:  Data Loading (10 points)\n",
    "Complete the **DataLoader** below which we will use to load images of the cifar10 dataset provided by torchvision. Your task is to normalize it by shifting and scaling it by a factor of 0.5. For the training set, introduce random transformations (e.g. flips) for data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EtxYeHjRVO9S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 169435136/170498071 [00:20<00:00, 6846049.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "# Just normalization for testing\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([transforms.RandomHorizontalFlip(0.5),\n",
    "                                 transforms.RandomResizedCrop(size=(32, 32), scale=(0.8, 1)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "                                ]),\n",
    "    'test': transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "                               ])\n",
    "}\n",
    "\n",
    "# Load CIFAR10\n",
    "image_datasets = {x: torchvision.datasets.CIFAR10(root='./data', train=(x=='train'), download=True, transform=data_transforms[x]) for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, shuffle=(x=='train'), num_workers=4) for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Move to GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uS6cR4RhVO9U"
   },
   "source": [
    "### Visualize a few images\n",
    "\n",
    "Let’s visualize a few training images so as to understand the data augmentations. The results should look like:\n",
    "\n",
    "<img src=\"https://i.imgur.com/Sa6l1go.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xXSA5DDBVO9V"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "170500096it [00:40, 6846049.78it/s]                               "
     ]
    }
   ],
   "source": [
    "# TODO Task 1:  Run this cell and try to understand the output of each step\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmMMSK0TVO9L"
   },
   "source": [
    "## Task 2: Basic Networks (20 points)\n",
    "1. Create a Fully connected Network (FcNet) as follows in the Jupyter Notebook:\n",
    "```\n",
    "FcNet(\n",
    "  (fc1): Linear(in_features=3072, out_features=1024, bias=True)\n",
    "  (fc2): Linear(in_features=1024, out_features=400, bias=True)\n",
    "  (fc3): Linear(in_features=400, out_features=84, bias=True)\n",
    "  (fc4): Linear(in_features=84, out_features=10, bias=True)\n",
    ")\n",
    "```\n",
    "Train the FcNet for **3** epoches and record the training time and accuracy in your final report.\n",
    "\n",
    "2. Create a Convolutional Network (ConvNet) as follows in the Jupyter Notebook:\n",
    "```\n",
    "ConvNet(\n",
    "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
    "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
    "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
    ")\n",
    "```\n",
    "Train the ConvNet for **3** epoches and record the training time and accuracy in your final report. \n",
    "\n",
    "*Use the default SGD optimizer ( lr=0.001, momentum=0.9) for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sKXg8fSVO9X"
   },
   "source": [
    "### Model training code (do not modify except for plotting the loss curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_Y2cgPEVO9X"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, num_epochs=25, save_path='saved_weight.pth'):\n",
    "    since = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train']:\n",
    "            if phase == 'train': model.train()  # Set model to training mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "    print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    torch.save(model.state_dict(), save_path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tX6I8cqXFDMX"
   },
   "source": [
    "### 1) FC Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpompN92VO9d"
   },
   "outputs": [],
   "source": [
    "# 1) Define a Fully Connected Neural Network\n",
    "class FcNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FcNet, self).__init__()\n",
    "        # TODO Task 2:  Define the layers \n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Task 2:  Define the forward pass\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_ft = FcNet()\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFQdcJaKFF8y"
   },
   "source": [
    "### 2) CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ma36XwVfVO9h"
   },
   "outputs": [],
   "source": [
    "# 2) Define a Convolutional Neural Network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # TODO Task 2:  Define the CNN layers \n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Task 2:  Define the forward pass\n",
    "        \n",
    "        return x\n",
    "\n",
    "model_ft = ConvNet()\n",
    "model_ft = model_ft.to(device)\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NMAIB0f8VO9M"
   },
   "source": [
    "## Task 3: Design Your Network I (20 points)\n",
    "Define your own Convolutional Network (MyNet) starting from the configuration in Task 2.2. Add following modifications and train the Network for **25** epoches. Keep the best settings for each step (for each step, record the training accuracy of the last epoch and test accuracy in your report):\n",
    "\n",
    "1. Increase the number of layers: Modify the number of convolutional layers in the network.\n",
    "2. Increase the number of filters: Modify the number of filters in each convolutional layer of the network. \n",
    "3. Modify the filter sizes in each convolutional layer. Experiment with different filter sizes (3x3, 5x5 and 7x7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fkrcMarLVO9N"
   },
   "source": [
    "## Task 4: Design Your Network II (20 points)\n",
    "Keeping the best settings of Task 3, use **Dropout** in fully connected layers and Batch Normalization (choose a suitable batch size) in convolutional layers. Record the training accuracy of the last epoch and test accuracy in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "biQSr45WKS86"
   },
   "source": [
    "### Design Your Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpRAJHrtVO9o"
   },
   "outputs": [],
   "source": [
    "# Define a Convolutional Neural Network\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        # TODO Task 3 & 4: Design Your Network I & II \n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Task 3 & 4: Design Your Network I & II\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "77S-thkZVO9q"
   },
   "outputs": [],
   "source": [
    "model_ft = MyNet()\n",
    "model_ft = model_ft.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# TODO Task 5: Optimizer\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KYLl8I42VO9r"
   },
   "outputs": [],
   "source": [
    "## Train and evaluate\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "akFMVbNaVO9N"
   },
   "source": [
    "## Task 5: The Optimizer (20 points)\n",
    "Keeping the best settings of Task 4, use 3 different optimizers (SGD, ADAM and RMSProp) with 3 different learning rates (0.001, 0.01, 0.1) . Plot the loss curves (Training loss vs Training step) for each case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bl7mS2igVO9v"
   },
   "source": [
    "### Testing the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GtE6iv9rVO9w"
   },
   "outputs": [],
   "source": [
    "def test_model(model, load_path='saved_weight.pth'):    \n",
    "    # load the model weights\n",
    "    model.load_state_dict(torch.load(load_path))\n",
    "    \n",
    "    since = time.time()\n",
    "\n",
    "    for phase in ['test']:\n",
    "        if phase == 'test':\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in dataloaders[phase]:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            # statistics\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print('{} Acc: {:.4f}'.format(phase, epoch_acc))\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Testing complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ZI4TK9jVO9y"
   },
   "outputs": [],
   "source": [
    "test_model(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display model predictions\n",
    "## Generic function to display predictions for a few images\n",
    "\n",
    "def display_predictions(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_predictions(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E-A_mLSoVO9O"
   },
   "source": [
    "## Task 6: Visualization (10 points)\n",
    "Visualize feature maps of the first and the last convolutional layer of your final network using **cifar_example.jpg** as input image. Show the visualization in the report.\n",
    "\n",
    "#### First layer activations\n",
    "<img src=\"https://i.imgur.com/kGB9AuP.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TsbbsIGKVO9P"
   },
   "source": [
    "#### Last layer activations\n",
    "\n",
    "<img src=\"https://i.imgur.com/qelH05X.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vmlGWrPwVO90"
   },
   "source": [
    "## Save the Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IhQxWX8RVO91"
   },
   "outputs": [],
   "source": [
    "# TODO Task 6: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gNX3eVEyVO94"
   },
   "outputs": [],
   "source": [
    "def transfer_single_img_to_tensor(img_path):\n",
    "    im = Image.open(img_path)\n",
    "    img = np.asarray(im)/255\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    \n",
    "    inp = (img - mean) / std\n",
    "    inp = np.asarray(inp, dtype=np.float32)\n",
    "    inp = inp.transpose((2, 0, 1))\n",
    "    inp = np.expand_dims(inp, axis=0)\n",
    "    inp = torch.from_numpy(inp, )\n",
    "    inputs = inp.to(device)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L0AqVUu9VO97"
   },
   "outputs": [],
   "source": [
    "inputs = transfer_single_img_to_tensor('example_imgs/cifar_example.jpg')\n",
    "model_ft.eval()\n",
    "with torch.no_grad():\n",
    "    model_ft(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I4Y-bqt2VO99"
   },
   "outputs": [],
   "source": [
    "# Model_ft.featuremap1 and model_ft.featuremap2 should be the first and the last feature maps.\n",
    "# Add model_ft.featuremap1 and model_ft.featuremap2 at suitable places in your network\n",
    "\n",
    "feature_ouput1 = model_ft.featuremap1.transpose(1,0).cpu()\n",
    "feature_ouput2 = model_ft.featuremap2.transpose(1,0).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m4Qy8s4BVO9_"
   },
   "outputs": [],
   "source": [
    "def feature_imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.detach().numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ofvGE8-VO-B"
   },
   "outputs": [],
   "source": [
    "out = torchvision.utils.make_grid(feature_ouput1)\n",
    "feature_imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Mo1xtSzVO-E"
   },
   "outputs": [],
   "source": [
    "out = torchvision.utils.make_grid(feature_ouput2)\n",
    "feature_imshow(out)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_Image_Classification.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
